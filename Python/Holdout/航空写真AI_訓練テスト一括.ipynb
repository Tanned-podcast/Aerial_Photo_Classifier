{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ef446-4d2c-47bf-a8b4-b9ca9dc766a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:60: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:186: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:243: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:286: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:390: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:60: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:186: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:243: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:286: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:390: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\kyohe\\AppData\\Local\\Temp\\ipykernel_9656\\3408535223.py:60: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  self.data = list(sorted(Path(root).glob(\"*\\*\")))\n",
      "C:\\Users\\kyohe\\AppData\\Local\\Temp\\ipykernel_9656\\3408535223.py:186: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  savepath2 = Path(savepath+\"\\\\\"+str(e1)+\"\\model_weights\"+filedate+\".pth\")\n",
      "C:\\Users\\kyohe\\AppData\\Local\\Temp\\ipykernel_9656\\3408535223.py:243: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  epochmodelpath = Path(savepath+\"\\\\\"+str(e)+\"\\model_weights\"+filedate+(f\"_fold{fold}\" if fold else \"\")+\".pth\")\n",
      "C:\\Users\\kyohe\\AppData\\Local\\Temp\\ipykernel_9656\\3408535223.py:286: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  bestmodelpath = Path(savepath+\"\\\\\"+str(bestepoch)+\"\\model_weights\"+filedate+(f\"_fold{fold}\" if fold else \"\")+\".pth\")\n",
      "C:\\Users\\kyohe\\AppData\\Local\\Temp\\ipykernel_9656\\3408535223.py:390: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  datepath=str(Path(resultspath + \"\\calc_time_\" + filedate + \".txt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0 IMGSIZE:( 3 224 224 ) BatchSize: 64 Epochs: 200 Valsplit: 0.25 Class: ['Intact', 'Damaged']\n",
      "TrainData Size: 21195 TrainData Batches 332 ValData Size: 7065 ValData Batches: 111\n",
      "Epoch 1 TrainLoss: 0.5931 TrainAcc: 0.6796\n",
      "Epoch 1 ValLoss: 0.6369 ValAcc: 0.6285\n",
      " \n",
      "Epoch 2 TrainLoss: 0.5164 TrainAcc: 0.7399\n",
      "Epoch 2 ValLoss: 0.5198 ValAcc: 0.7370\n",
      " \n",
      "Epoch 3 TrainLoss: 0.4629 TrainAcc: 0.7772\n",
      "Epoch 3 ValLoss: 0.4905 ValAcc: 0.7539\n",
      " \n",
      "Epoch 4 TrainLoss: 0.4192 TrainAcc: 0.8030\n",
      "Epoch 4 ValLoss: 0.4320 ValAcc: 0.7948\n",
      " \n",
      "Epoch 5 TrainLoss: 0.3676 TrainAcc: 0.8321\n",
      "Epoch 5 ValLoss: 0.4462 ValAcc: 0.7880\n",
      " \n",
      "Epoch 6 TrainLoss: 0.3135 TrainAcc: 0.8617\n",
      "Epoch 6 ValLoss: 0.4042 ValAcc: 0.8102\n",
      " \n",
      "Epoch 7 TrainLoss: 0.2530 TrainAcc: 0.8909\n",
      "Epoch 7 ValLoss: 0.3113 ValAcc: 0.8596\n",
      " \n",
      "Epoch 8 TrainLoss: 0.1914 TrainAcc: 0.9206\n",
      "Epoch 8 ValLoss: 0.2953 ValAcc: 0.8746\n",
      " \n",
      "Epoch 9 TrainLoss: 0.1356 TrainAcc: 0.9476\n",
      "Epoch 9 ValLoss: 0.3285 ValAcc: 0.8626\n",
      " \n",
      "Epoch 10 TrainLoss: 0.0964 TrainAcc: 0.9652\n",
      "Epoch 10 ValLoss: 0.1483 ValAcc: 0.9407\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\10\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 11 TrainLoss: 0.0700 TrainAcc: 0.9752\n",
      "Epoch 11 ValLoss: 0.1971 ValAcc: 0.9183\n",
      " \n",
      "Epoch 12 TrainLoss: 0.0518 TrainAcc: 0.9811\n",
      "Epoch 12 ValLoss: 0.1608 ValAcc: 0.9360\n",
      " \n",
      "Epoch 13 TrainLoss: 0.0429 TrainAcc: 0.9857\n",
      "Epoch 13 ValLoss: 0.0990 ValAcc: 0.9605\n",
      " \n",
      "Epoch 14 TrainLoss: 0.0350 TrainAcc: 0.9878\n",
      "Epoch 14 ValLoss: 0.1546 ValAcc: 0.9424\n",
      " \n",
      "Epoch 15 TrainLoss: 0.0301 TrainAcc: 0.9905\n",
      "Epoch 15 ValLoss: 0.1270 ValAcc: 0.9558\n",
      " \n",
      "Epoch 16 TrainLoss: 0.0213 TrainAcc: 0.9935\n",
      "Epoch 16 ValLoss: 0.0588 ValAcc: 0.9798\n",
      " \n",
      "Epoch 17 TrainLoss: 0.0168 TrainAcc: 0.9946\n",
      "Epoch 17 ValLoss: 0.0626 ValAcc: 0.9779\n",
      " \n",
      "Epoch 18 TrainLoss: 0.0151 TrainAcc: 0.9955\n",
      "Epoch 18 ValLoss: 0.0574 ValAcc: 0.9812\n",
      " \n",
      "Epoch 19 TrainLoss: 0.0138 TrainAcc: 0.9963\n",
      "Epoch 19 ValLoss: 0.0628 ValAcc: 0.9779\n",
      " \n",
      "Epoch 20 TrainLoss: 0.0175 TrainAcc: 0.9956\n",
      "Epoch 20 ValLoss: 0.0777 ValAcc: 0.9721\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\20\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 21 TrainLoss: 0.0238 TrainAcc: 0.9927\n",
      "Epoch 21 ValLoss: 0.0581 ValAcc: 0.9782\n",
      " \n",
      "Epoch 22 TrainLoss: 0.0149 TrainAcc: 0.9961\n",
      "Epoch 22 ValLoss: 0.0513 ValAcc: 0.9826\n",
      " \n",
      "Epoch 23 TrainLoss: 0.0119 TrainAcc: 0.9968\n",
      "Epoch 23 ValLoss: 0.0320 ValAcc: 0.9898\n",
      " \n",
      "Epoch 24 TrainLoss: 0.0118 TrainAcc: 0.9966\n",
      "Epoch 24 ValLoss: 0.0339 ValAcc: 0.9887\n",
      " \n",
      "Epoch 25 TrainLoss: 0.0097 TrainAcc: 0.9975\n",
      "Epoch 25 ValLoss: 0.0358 ValAcc: 0.9885\n",
      " \n",
      "Epoch 26 TrainLoss: 0.0107 TrainAcc: 0.9967\n",
      "Epoch 26 ValLoss: 0.0352 ValAcc: 0.9885\n",
      " \n",
      "Epoch 27 TrainLoss: 0.0059 TrainAcc: 0.9987\n",
      "Epoch 27 ValLoss: 0.0291 ValAcc: 0.9897\n",
      " \n",
      "Epoch 28 TrainLoss: 0.0047 TrainAcc: 0.9988\n",
      "Epoch 28 ValLoss: 0.0285 ValAcc: 0.9914\n",
      " \n",
      "Epoch 29 TrainLoss: 0.0058 TrainAcc: 0.9983\n",
      "Epoch 29 ValLoss: 0.0172 ValAcc: 0.9949\n",
      " \n",
      "Epoch 30 TrainLoss: 0.0046 TrainAcc: 0.9989\n",
      "Epoch 30 ValLoss: 0.0211 ValAcc: 0.9919\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\30\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 31 TrainLoss: 0.0037 TrainAcc: 0.9991\n",
      "Epoch 31 ValLoss: 0.0320 ValAcc: 0.9900\n",
      " \n",
      "Epoch 32 TrainLoss: 0.0044 TrainAcc: 0.9986\n",
      "Epoch 32 ValLoss: 0.0284 ValAcc: 0.9907\n",
      " \n",
      "Epoch 33 TrainLoss: 0.0040 TrainAcc: 0.9991\n",
      "Epoch 33 ValLoss: 0.0304 ValAcc: 0.9905\n",
      " \n",
      "Epoch 34 TrainLoss: 0.0037 TrainAcc: 0.9991\n",
      "Epoch 34 ValLoss: 0.0239 ValAcc: 0.9919\n",
      " \n",
      "Epoch 35 TrainLoss: 0.0047 TrainAcc: 0.9988\n",
      "Epoch 35 ValLoss: 0.0219 ValAcc: 0.9941\n",
      " \n",
      "Epoch 36 TrainLoss: 0.0039 TrainAcc: 0.9989\n",
      "Epoch 36 ValLoss: 0.0172 ValAcc: 0.9946\n",
      " \n",
      "Epoch 37 TrainLoss: 0.0047 TrainAcc: 0.9986\n",
      "Epoch 37 ValLoss: 0.0149 ValAcc: 0.9949\n",
      " \n",
      "Epoch 38 TrainLoss: 0.0039 TrainAcc: 0.9990\n",
      "Epoch 38 ValLoss: 0.0229 ValAcc: 0.9915\n",
      " \n",
      "Epoch 39 TrainLoss: 0.0031 TrainAcc: 0.9992\n",
      "Epoch 39 ValLoss: 0.0150 ValAcc: 0.9953\n",
      " \n",
      "Epoch 40 TrainLoss: 0.0027 TrainAcc: 0.9994\n",
      "Epoch 40 ValLoss: 0.0192 ValAcc: 0.9935\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\40\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 41 TrainLoss: 0.0025 TrainAcc: 0.9994\n",
      "Epoch 41 ValLoss: 0.0200 ValAcc: 0.9926\n",
      " \n",
      "Epoch 42 TrainLoss: 0.0029 TrainAcc: 0.9992\n",
      "Epoch 42 ValLoss: 0.0163 ValAcc: 0.9945\n",
      " \n",
      "Epoch 43 TrainLoss: 0.0018 TrainAcc: 0.9996\n",
      "Epoch 43 ValLoss: 0.0169 ValAcc: 0.9946\n",
      " \n",
      "Epoch 44 TrainLoss: 0.0030 TrainAcc: 0.9992\n",
      "Epoch 44 ValLoss: 0.0194 ValAcc: 0.9926\n",
      " \n",
      "Epoch 45 TrainLoss: 0.0058 TrainAcc: 0.9982\n",
      "Epoch 45 ValLoss: 0.0235 ValAcc: 0.9922\n",
      " \n",
      "Epoch 46 TrainLoss: 0.0021 TrainAcc: 0.9994\n",
      "Epoch 46 ValLoss: 0.0158 ValAcc: 0.9950\n",
      " \n",
      "Epoch 47 TrainLoss: 0.0017 TrainAcc: 0.9995\n",
      "Epoch 47 ValLoss: 0.0156 ValAcc: 0.9945\n",
      " \n",
      "Epoch 48 TrainLoss: 0.0015 TrainAcc: 0.9996\n",
      "Epoch 48 ValLoss: 0.0168 ValAcc: 0.9948\n",
      " \n",
      "Epoch 49 TrainLoss: 0.0022 TrainAcc: 0.9993\n",
      "Epoch 49 ValLoss: 0.0194 ValAcc: 0.9942\n",
      " \n",
      "Epoch 50 TrainLoss: 0.0016 TrainAcc: 0.9995\n",
      "Epoch 50 ValLoss: 0.0158 ValAcc: 0.9955\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\50\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 51 TrainLoss: 0.0019 TrainAcc: 0.9996\n",
      "Epoch 51 ValLoss: 0.0171 ValAcc: 0.9956\n",
      " \n",
      "Epoch 52 TrainLoss: 0.0016 TrainAcc: 0.9995\n",
      "Epoch 52 ValLoss: 0.0156 ValAcc: 0.9946\n",
      " \n",
      "Epoch 53 TrainLoss: 0.0017 TrainAcc: 0.9995\n",
      "Epoch 53 ValLoss: 0.0141 ValAcc: 0.9960\n",
      " \n",
      "Epoch 54 TrainLoss: 0.0011 TrainAcc: 0.9998\n",
      "Epoch 54 ValLoss: 0.0112 ValAcc: 0.9965\n",
      " \n",
      "Epoch 55 TrainLoss: 0.0013 TrainAcc: 0.9998\n",
      "Epoch 55 ValLoss: 0.0114 ValAcc: 0.9966\n",
      " \n",
      "Epoch 56 TrainLoss: 0.0014 TrainAcc: 0.9997\n",
      "Epoch 56 ValLoss: 0.0166 ValAcc: 0.9943\n",
      " \n",
      "Epoch 57 TrainLoss: 0.0029 TrainAcc: 0.9991\n",
      "Epoch 57 ValLoss: 0.0266 ValAcc: 0.9919\n",
      " \n",
      "Epoch 58 TrainLoss: 0.0044 TrainAcc: 0.9987\n",
      "Epoch 58 ValLoss: 0.0300 ValAcc: 0.9902\n",
      " \n",
      "Epoch 59 TrainLoss: 0.0064 TrainAcc: 0.9983\n",
      "Epoch 59 ValLoss: 0.0186 ValAcc: 0.9939\n",
      " \n",
      "Epoch 60 TrainLoss: 0.0016 TrainAcc: 0.9998\n",
      "Epoch 60 ValLoss: 0.0141 ValAcc: 0.9955\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\60\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 61 TrainLoss: 0.0017 TrainAcc: 0.9994\n",
      "Epoch 61 ValLoss: 0.0154 ValAcc: 0.9956\n",
      " \n",
      "Epoch 62 TrainLoss: 0.0016 TrainAcc: 0.9995\n",
      "Epoch 62 ValLoss: 0.0144 ValAcc: 0.9941\n",
      " \n",
      "Epoch 63 TrainLoss: 0.0014 TrainAcc: 0.9996\n",
      "Epoch 63 ValLoss: 0.0139 ValAcc: 0.9956\n",
      " \n",
      "Epoch 64 TrainLoss: 0.0011 TrainAcc: 1.0000\n",
      "Epoch 64 ValLoss: 0.0130 ValAcc: 0.9955\n",
      " \n",
      "Epoch 65 TrainLoss: 0.0047 TrainAcc: 0.9987\n",
      "Epoch 65 ValLoss: 0.0121 ValAcc: 0.9962\n",
      " \n",
      "Epoch 66 TrainLoss: 0.0016 TrainAcc: 0.9994\n",
      "Epoch 66 ValLoss: 0.0122 ValAcc: 0.9958\n",
      " \n",
      "Epoch 67 TrainLoss: 0.0011 TrainAcc: 0.9997\n",
      "Epoch 67 ValLoss: 0.0199 ValAcc: 0.9936\n",
      " \n",
      "Epoch 68 TrainLoss: 0.0014 TrainAcc: 0.9997\n",
      "Epoch 68 ValLoss: 0.0096 ValAcc: 0.9966\n",
      " \n",
      "Epoch 69 TrainLoss: 0.0014 TrainAcc: 0.9997\n",
      "Epoch 69 ValLoss: 0.0135 ValAcc: 0.9962\n",
      " \n",
      "Epoch 70 TrainLoss: 0.0012 TrainAcc: 0.9998\n",
      "Epoch 70 ValLoss: 0.0119 ValAcc: 0.9960\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\70\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 71 TrainLoss: 0.0008 TrainAcc: 0.9998\n",
      "Epoch 71 ValLoss: 0.0114 ValAcc: 0.9958\n",
      " \n",
      "Epoch 72 TrainLoss: 0.0009 TrainAcc: 0.9998\n",
      "Epoch 72 ValLoss: 0.0112 ValAcc: 0.9960\n",
      " \n",
      "Epoch 73 TrainLoss: 0.0006 TrainAcc: 0.9999\n",
      "Epoch 73 ValLoss: 0.0098 ValAcc: 0.9960\n",
      " \n",
      "Epoch 74 TrainLoss: 0.0007 TrainAcc: 0.9998\n",
      "Epoch 74 ValLoss: 0.0114 ValAcc: 0.9962\n",
      " \n",
      "Epoch 75 TrainLoss: 0.0010 TrainAcc: 0.9999\n",
      "Epoch 75 ValLoss: 0.0099 ValAcc: 0.9966\n",
      " \n",
      "Epoch 76 TrainLoss: 0.0008 TrainAcc: 0.9998\n",
      "Epoch 76 ValLoss: 0.0117 ValAcc: 0.9959\n",
      " \n",
      "Epoch 77 TrainLoss: 0.0011 TrainAcc: 0.9998\n",
      "Epoch 77 ValLoss: 0.0114 ValAcc: 0.9960\n",
      " \n",
      "Epoch 78 TrainLoss: 0.0009 TrainAcc: 0.9999\n",
      "Epoch 78 ValLoss: 0.0088 ValAcc: 0.9963\n",
      " \n",
      "Epoch 79 TrainLoss: 0.0055 TrainAcc: 0.9999\n",
      "Epoch 79 ValLoss: 0.0204 ValAcc: 0.9942\n",
      " \n",
      "Epoch 80 TrainLoss: 0.0064 TrainAcc: 0.9980\n",
      "Epoch 80 ValLoss: 0.0146 ValAcc: 0.9950\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\80\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 81 TrainLoss: 0.0051 TrainAcc: 0.9989\n",
      "Epoch 81 ValLoss: 0.0296 ValAcc: 0.9900\n",
      " \n",
      "Epoch 82 TrainLoss: 0.0124 TrainAcc: 0.9960\n",
      "Epoch 82 ValLoss: 0.0181 ValAcc: 0.9929\n",
      " \n",
      "Epoch 83 TrainLoss: 0.0048 TrainAcc: 0.9991\n",
      "Epoch 83 ValLoss: 0.0842 ValAcc: 0.9761\n",
      " \n",
      "Epoch 84 TrainLoss: 0.0076 TrainAcc: 0.9975\n",
      "Epoch 84 ValLoss: 0.0182 ValAcc: 0.9926\n",
      " \n",
      "Epoch 85 TrainLoss: 0.0046 TrainAcc: 0.9991\n",
      "Epoch 85 ValLoss: 0.0176 ValAcc: 0.9946\n",
      " \n",
      "Epoch 86 TrainLoss: 0.0072 TrainAcc: 0.9976\n",
      "Epoch 86 ValLoss: 0.0234 ValAcc: 0.9928\n",
      " \n",
      "Epoch 87 TrainLoss: 0.0021 TrainAcc: 0.9993\n",
      "Epoch 87 ValLoss: 0.0130 ValAcc: 0.9953\n",
      " \n",
      "Epoch 88 TrainLoss: 0.0011 TrainAcc: 0.9998\n",
      "Epoch 88 ValLoss: 0.0139 ValAcc: 0.9956\n",
      " \n",
      "Epoch 89 TrainLoss: 0.0017 TrainAcc: 0.9995\n",
      "Epoch 89 ValLoss: 0.0132 ValAcc: 0.9952\n",
      " \n",
      "Epoch 90 TrainLoss: 0.0016 TrainAcc: 0.9995\n",
      "Epoch 90 ValLoss: 0.0128 ValAcc: 0.9953\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\90\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 91 TrainLoss: 0.0014 TrainAcc: 0.9997\n",
      "Epoch 91 ValLoss: 0.0099 ValAcc: 0.9965\n",
      " \n",
      "Epoch 92 TrainLoss: 0.0019 TrainAcc: 0.9995\n",
      "Epoch 92 ValLoss: 0.0097 ValAcc: 0.9966\n",
      " \n",
      "Epoch 93 TrainLoss: 0.0006 TrainAcc: 1.0000\n",
      "Epoch 93 ValLoss: 0.0121 ValAcc: 0.9960\n",
      " \n",
      "Epoch 94 TrainLoss: 0.0007 TrainAcc: 0.9999\n",
      "Epoch 94 ValLoss: 0.0087 ValAcc: 0.9965\n",
      " \n",
      "Epoch 95 TrainLoss: 0.0010 TrainAcc: 0.9998\n",
      "Epoch 95 ValLoss: 0.0080 ValAcc: 0.9970\n",
      " \n",
      "Epoch 96 TrainLoss: 0.0011 TrainAcc: 0.9997\n",
      "Epoch 96 ValLoss: 0.0071 ValAcc: 0.9977\n",
      " \n",
      "Epoch 97 TrainLoss: 0.0021 TrainAcc: 0.9996\n",
      "Epoch 97 ValLoss: 0.0458 ValAcc: 0.9868\n",
      " \n",
      "Epoch 98 TrainLoss: 0.0075 TrainAcc: 0.9977\n",
      "Epoch 98 ValLoss: 0.0410 ValAcc: 0.9874\n",
      " \n",
      "Epoch 99 TrainLoss: 0.0040 TrainAcc: 0.9989\n",
      "Epoch 99 ValLoss: 0.0121 ValAcc: 0.9960\n",
      " \n",
      "Epoch 100 TrainLoss: 0.0014 TrainAcc: 0.9997\n",
      "Epoch 100 ValLoss: 0.0133 ValAcc: 0.9953\n",
      "Saving Model...\n",
      "Model saved in ..\\..\\20251209Data\\Weights\\100\\model_weights20251212_0256.pth\n",
      " \n",
      "Epoch 101 TrainLoss: 0.0013 TrainAcc: 0.9997\n",
      "Epoch 101 ValLoss: 0.0115 ValAcc: 0.9963\n",
      " \n",
      "Epoch 102 TrainLoss: 0.0033 TrainAcc: 0.9996\n",
      "Epoch 102 ValLoss: 0.0303 ValAcc: 0.9926\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "%matplotlib inline\n",
    "\n",
    "time = datetime.datetime.now()\n",
    "filedate=time.strftime('%Y%m%d_%H%M')\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# 定数の設定\n",
    "Channels = 3\n",
    "batch_size = 64\n",
    "IMG_SIZE = 224\n",
    "valsplit = 0.25\n",
    "epochlist=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]\n",
    "epochs = epochlist[-1]\n",
    "\n",
    "\n",
    "# クラスの設定\n",
    "Classes = [\"Intact\", \"Damaged\"]\n",
    "ClassNum = len(Classes)\n",
    "\n",
    "# パス設定\n",
    "trainpath = r\"..\\..\\20251209Data\\TrainVal_BrightContrast\"\n",
    "testpath = r\"..\\..\\20251209Data\\Test\"\n",
    "savepath = r\"..\\..\\20251209Data\\Weights\"\n",
    "historypath = r\"..\\..\\20251209Data\\History\"\n",
    "resultspath = r\"..\\..\\20251209Data\\Results\"\n",
    "\n",
    "'''\n",
    "PytorchではDataloaderという,膨大なデータセットからでもメモリを圧迫せずに取り出せてforループにも対応するための枠組みがある\n",
    "データセットをDataloaderが引っ張ってこれるような形式にするためにMyDataset(torch.utils.data.Dataset)というクラスを作れば，\n",
    "あとはそのメソッドをtorch.utils.data.Datasetが勝手に使用してデータを加工してくれる\n",
    "__init__, __getitem__, __len__をクラス内で必ず定義しなければならない\n",
    "Dataloader内のデータはバッチごとにまとめられる\n",
    "'''\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root: str, transforms, Classes) -> None:\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.Classes = Classes\n",
    "        #globは複数のファイルのパスをまとめて取得する\n",
    "        #訓練と訓練白黒の二個下のディレクトリから画像を取得\n",
    "        self.data = list(sorted(Path(root).glob(\"*\\*\")))\n",
    "\n",
    "    #__getitem__は，MyDataset型のインスタンスでdataset[1]みたいに要素番号呼び出しをされたときに自動で行う処理(Pythonデフォ付属)\n",
    "    # ここで取り出すデータを指定している\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        data = self.data[index]\n",
    "        #OpenCVで読み込むときは必ずRGBに変換\n",
    "        img1 = cv2.cvtColor(cv2.imread(str(data)), cv2.COLOR_BGR2RGB)\n",
    "        img1 = cv2.resize(img1, (IMG_SIZE, IMG_SIZE))\n",
    "        img1 = TF.to_tensor(img1)\n",
    "\n",
    "        # データの変形 (transforms)\n",
    "        transformed_img = self.transforms(img1)\n",
    "\n",
    "        #ラベル貼り：dataというパスを/で区切ってリストにし，クラス名のところをラベルに格納\n",
    "        #クラス名は文字列なので，self.Classesの要素と比較して一致するところの番号をラベルとする\n",
    "        label = str(data).split(\"\\\\\")[-2]\n",
    "        label = torch.tensor(self.Classes.index(label))\n",
    "\n",
    "        return transformed_img, label, str(data)\n",
    "\n",
    "    # この method がないと DataLoader を呼び出す際にエラーを吐かれる\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "#入力データに施す処理\n",
    "transforms = v2.Compose([\n",
    "        #v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0,0,0], std=[0.2, 0.2, 0.2]),\n",
    "])\n",
    "\n",
    "\n",
    "trainvalset = MyDataset(root=trainpath, transforms=transforms, Classes=Classes)\n",
    "trainset, valset = random_split(trainvalset, [1-valsplit, valsplit])\n",
    "\n",
    "trainloader = DataLoader(dataset=trainset,batch_size=batch_size,shuffle=True)\n",
    "valloader = DataLoader(dataset=valset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "# モデルの初期化関数\n",
    "def initialize_model():\n",
    "    model = models.resnet50(weights='DEFAULT')\n",
    "    #チャンネル数いじれるようにしておく\n",
    "    model.conv1 = torch.nn.Conv2d(Channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, ClassNum)\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "model = initialize_model()\n",
    "\n",
    "#lossfunction&optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(\"Device:\", device, \"IMGSIZE:(\", Channels, IMG_SIZE, IMG_SIZE, \")\",  \"BatchSize:\", batch_size, \"Epochs:\", epochs, \"Valsplit:\", valsplit, \"Class:\", Classes)\n",
    "\n",
    "'''\n",
    "trainiterator\n",
    "enumerateはtrainloader内のすべてのdataに対してループし，繰り返し回数をbatchに渡すという意味\n",
    "Dataloader内ではバッチごとにデータがまとめられるので1回の取り出しで1バッチ分のデータを丸々取り出せる\n",
    "'''\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "def train(trainloader, valloader, model, loss_fn, optimizer, epochs):\n",
    "    size = len(trainloader.dataset)\n",
    "    num_batches = len(trainloader)\n",
    "    size_val = len(valloader.dataset)\n",
    "    num_batches_val = len(valloader)\n",
    "    print(\"TrainData Size:\", size, \"TrainData Batches\", num_batches, \"ValData Size:\", size_val, \"ValData Batches:\", num_batches_val)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss, running_correct = 0, 0\n",
    "        val_loss, val_correct = 0, 0\n",
    "        for batch, (X, y, _) in enumerate(trainloader):\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #損失と正解数の合計を計算しておき，後でそのエポック内での平均をとる\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / num_batches\n",
    "        epoch_acc = running_correct / size\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "\n",
    "        print(f'Epoch {epoch + 1} TrainLoss: {epoch_loss:.4f} TrainAcc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "        model.eval()\n",
    "        # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "        # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "        with torch.no_grad():\n",
    "            for X, y, _ in valloader:\n",
    "                X=X.to(device)\n",
    "                y=y.to(device)\n",
    "                pred = model(X)\n",
    "                val_loss += loss_fn(pred, y).item()\n",
    "                val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "            val_loss /= num_batches_val\n",
    "            val_correct /= size_val\n",
    "        # Set the model to train mode\n",
    "        model.train()\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_correct)\n",
    "\n",
    "        print(f'Epoch {epoch + 1} ValLoss: {val_loss:.4f} ValAcc: {val_correct:.4f}')\n",
    "\n",
    "        #10epoch毎にパラメータを別々のフォルダに保存\n",
    "        e1=epoch+1\n",
    "        if (e1 % 10 == 0):\n",
    "            savepath2 = Path(savepath+\"\\\\\"+str(e1)+\"\\model_weights\"+filedate+\".pth\")\n",
    "            print('Saving Model...')\n",
    "            torch.save(model.state_dict(), savepath2)\n",
    "            print('Model saved in', savepath2)\n",
    "\n",
    "        print(' ')\n",
    "\n",
    "train(trainloader, valloader, model, loss_fn, optimizer, epochs)\n",
    "\n",
    "#グラフ可視化\n",
    "#pltの(x,y)のxにあたるepochのリスト　1から開始\n",
    "ep=np.arange(1, epochs+1)\n",
    "\n",
    "#グラフにプロットする正解率と損失のリストをCSVに書き出し to_csvは新規フォルダを作ってくれないのでosで作る\n",
    "historypath2 = str(Path(historypath+\"\\\\\"+filedate))\n",
    "os.mkdir(historypath2)\n",
    "pd.DataFrame(data=np.array([ep, train_accuracies]).T, columns=[\"Epoch\", \"Accuracy\"]).to_csv(Path(historypath2+\"\\\\\"+\"Train_Acc.csv\"))\n",
    "pd.DataFrame(data=np.array([ep, train_losses]).T, columns=[\"Epoch\", \"Loss\"]).to_csv(Path(historypath2+\"\\\\\"+\"Train_Loss.csv\"))\n",
    "pd.DataFrame(data=np.array([ep, val_accuracies]).T, columns=[\"Epoch\", \"Accuracy\"]).to_csv(Path(historypath2+\"\\\\\"+\"Val_Acc.csv\"))\n",
    "pd.DataFrame(data=np.array([ep, val_losses]).T, columns=[\"Epoch\", \"Loss\"]).to_csv(Path(historypath2+\"\\\\\"+\"Val_Loss.csv\"))\n",
    "print(\"CSVs saved in\", historypath2)\n",
    "\n",
    "def plot_acc(train_accuracies, val_accuracies):\n",
    "    plt.plot(ep, train_accuracies)\n",
    "    plt.plot(ep, val_accuracies)\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.xticks(np.arange(0, epochs+1, 10))\n",
    "    plt.yticks(np.arange(0.0, 1.05, 0.05))\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.plot(ep, train_losses)\n",
    "    plt.plot(ep, val_losses)\n",
    "    plt.title(\"model loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.xticks(np.arange(0, epochs+1, 10))\n",
    "    plt.ylim(bottom=-5, top=10)\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_acc(train_accuracies, val_accuracies)\n",
    "plot_loss(train_losses, val_losses)\n",
    "\n",
    "print('Training Finished!!!')\n",
    "\n",
    "\n",
    "#各エポックのモデルを評価する\n",
    "def BestEpochModel_Evaluate(testloader, loss_fn, fold=None):\n",
    "    epochmodel_accuracies=[]\n",
    "    \n",
    "    #各エポックで止めたモデルの中から最良のモデルを選択\n",
    "    for e in epochlist:\n",
    "        #モデル構築\n",
    "        epochmodelpath = Path(savepath+\"\\\\\"+str(e)+\"\\model_weights\"+filedate+(f\"_fold{fold}\" if fold else \"\")+\".pth\")\n",
    "        epochmodel = initialize_model()\n",
    "        epochmodel.load_state_dict(torch.load(epochmodelpath))\n",
    "        #GPUにニューラルネットワークを渡す\n",
    "        epochmodel=epochmodel.to(device)\n",
    "    \n",
    "        print(\"Model in Epoch\", e)\n",
    "        # テストデータでの評価\n",
    "        epochmodel.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        file_paths = []\n",
    "        size_test = len(testloader.dataset)\n",
    "        test_loss, test_correct = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y, paths in testloader:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                outputs = epochmodel(X)\n",
    "                #torch.maxの一番目の戻り値は確率．二番目の戻り値は，クラス番号　なのでクラス番号だけ取り出す\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                test_loss += loss_fn(outputs, y).item()\n",
    "                test_correct += (outputs.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "            test_correct /= size_test\n",
    "\n",
    "        epochmodel_accuracies.append(test_correct)\n",
    "        \n",
    "        print(\"Loss: \", test_loss)\n",
    "        print(\"Accuracy: \", test_correct)\n",
    "        print()\n",
    "\n",
    "    #エポックと精度の対応表からベストモデル算定\n",
    "    ep_acc_df= pd.DataFrame({\n",
    "        \"epoch\": epochlist, \n",
    "        \"accuracy\": epochmodel_accuracies\n",
    "    })\n",
    "    \n",
    "    bestepoch = ep_acc_df.loc[ep_acc_df[\"accuracy\"].idxmax(), \"epoch\"]\n",
    "\n",
    "    #ベストモデル構築\n",
    "    bestmodelpath = Path(savepath+\"\\\\\"+str(bestepoch)+\"\\model_weights\"+filedate+(f\"_fold{fold}\" if fold else \"\")+\".pth\")\n",
    "    bestmodel = initialize_model()\n",
    "    bestmodel.load_state_dict(torch.load(bestmodelpath))\n",
    "    #GPUにニューラルネットワークを渡す\n",
    "    bestmodel=bestmodel.to(device)\n",
    "    \n",
    "    print(\"best epoch: \", bestepoch)\n",
    "\n",
    "    return bestmodel\n",
    "\n",
    "# 評価関数（混同行列と分類結果をCSVに出力）\n",
    "def evaluate_model(model, testloader, loss_fn, fold=None):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    file_paths = []\n",
    "    size_test = len(testloader.dataset)\n",
    "    test_loss, test_correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y, paths in testloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = model(X)\n",
    "            #torch.maxの一番目の戻り値は確率．二番目の戻り値は，クラス番号　なのでクラス番号だけ取り出す\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss_fn(outputs, y).item()\n",
    "            test_correct += (outputs.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "            #appendでリストにリストを追加するとリスト内にリストがある二重状態になってしまう　extend関数で2重リストにすることなく格納\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            file_paths.extend(paths)\n",
    "\n",
    "        test_correct /= size_test\n",
    "\n",
    "    print(f'TestLoss: {test_loss:.4f} TestAcc: {test_correct:.4f}')\n",
    "    \n",
    "    # 混同行列の作成\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # 結果を出力\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # 分類レポートの出力\n",
    "    report = classification_report(y_true, y_pred, target_names=Classes)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # 分類結果をCSVに出力\n",
    "    results_df = pd.DataFrame({\n",
    "        'FilePath': file_paths,\n",
    "        'TrueLabel': [Classes[i] for i in y_true],\n",
    "        'PredictedLabel': [Classes[i] for i in y_pred],\n",
    "        'Correct': [y_true[i] == y_pred[i] for i in range(len(y_true))]\n",
    "    })\n",
    "    \n",
    "    # 結果ディレクトリがなければ作成\n",
    "    os.makedirs(resultspath, exist_ok=True)\n",
    "    \n",
    "    # foldが指定されている場合は、フォルドごとの結果ファイルを作成\n",
    "    if fold is not None:\n",
    "        csv_path = os.path.join(resultspath, f\"classification_results_fold{fold}_{filedate}.csv\")\n",
    "    else:\n",
    "        csv_path = os.path.join(resultspath, f\"classification_results_{filedate}.csv\")\n",
    "    \n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Classification results saved to: {csv_path}\")\n",
    "    \n",
    "    return cm, results_df, test_loss, test_correct\n",
    "\n",
    "# 混同行列の可視化\n",
    "def plot_confusion_matrix(cm, fold=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=Classes, yticklabels=Classes)\n",
    "    plt.title('Confusion Matrix' + (f\" - Fold {fold}\" if fold else \"\"))\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # 保存\n",
    "    history_fold_path = historypath + \"\\\\\" + filedate + (f\"_fold{fold}\" if fold else \"\")\n",
    "    os.makedirs(history_fold_path, exist_ok=True)\n",
    "    plt.savefig(os.path.join(history_fold_path, \"confusion_matrix.png\"))\n",
    "    plt.show()\n",
    "\n",
    "testset= MyDataset(root=testpath, transforms=transforms, Classes=Classes)\n",
    "\n",
    "testloader = DataLoader(dataset=testset,batch_size=len(testset),shuffle=True)\n",
    "\n",
    "bestmodel = BestEpochModel_Evaluate(testloader, loss_fn)\n",
    "        \n",
    "cm, results_df, test_loss, test_correct = evaluate_model(bestmodel, testloader, loss_fn)\n",
    "\n",
    "# 混同行列の可視化\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# 最終精度をprint\n",
    "print(f\"-Test Loss: {test_loss:.4f} Test Accuracy: {test_correct:.4f}\")\n",
    "\n",
    "# 計算終了時間の取得とフォーマット\n",
    "finishtime = datetime.datetime.now()\n",
    "finishdate = finishtime.strftime('%Y%m%d_%H%M')\n",
    "datepath=str(Path(resultspath + \"\\calc_time_\" + filedate + \".txt\"))\n",
    "\n",
    "# ファイルを新規作成し、日付を書き込む\n",
    "with open(datepath, 'w', encoding='utf-8') as f:\n",
    "    f.write(filedate)\n",
    "    f.write(finishdate)\n",
    "\n",
    "print(\"Calculation Finished in \", finishdate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
