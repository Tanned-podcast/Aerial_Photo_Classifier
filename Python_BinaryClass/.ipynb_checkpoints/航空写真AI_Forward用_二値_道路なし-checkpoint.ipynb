{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870e9ff9-ef4c-4981-8f54-3db51385eed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1  col_2  col_3\n",
      "row_0      0      1      2      3\n",
      "row_1      4      5      6      7\n",
      "row_2      8      9     10     11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
    "                  columns=['col_0', 'col_1', 'col_2', 'col_3'],\n",
    "                  index=['row_0', 'row_1', 'row_2'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec80a48-c1a5-47ad-a512-041c371658d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n",
      "w\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "a=[1, 1, 1]\n",
    "for i in range(len(a)):\n",
    "    print(\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c9c9d1-424f-4ae3-a7dd-739f10574645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241023_1626\n",
      "(64,)\n",
      "1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\kyohe\\\\Aerial-Photo-Classifier\\\\20241023Data\\\\Weights\\\\20\\\\model_weights20241023_1626.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 156\u001b[0m\n\u001b[0;32m    154\u001b[0m modelpath \u001b[38;5;241m=\u001b[39m Path(savepath\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(target_epoch)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfiledate\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    155\u001b[0m epochmodel \u001b[38;5;241m=\u001b[39m resnet50\n\u001b[1;32m--> 156\u001b[0m epochmodel\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m#GPUにニューラルネットワークを渡す\u001b[39;00m\n\u001b[0;32m    158\u001b[0m epochmodel\u001b[38;5;241m=\u001b[39mepochmodel\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\kyohe\\\\Aerial-Photo-Classifier\\\\20241023Data\\\\Weights\\\\20\\\\model_weights20241023_1626.pth'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "date=20241023\n",
    "time=1602\n",
    "filedate=str(date)+\"_\"+str(time)\n",
    "print(filedate)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "Channels=3\n",
    "IMG_SIZE=224\n",
    "target_epoch=20\n",
    "\n",
    "Classes = [\"Damage\", \"NoDamage\"]\n",
    "ClassNum = len(Classes)\n",
    "\n",
    "testpath=r\"C:\\Users\\kyohe\\Aerial-Photo-Classifier\\20241023Data\\Test\"\n",
    "savepath=r\"C:\\Users\\kyohe\\Aerial-Photo-Classifier\\20241023Data\\Weights\"\n",
    "forwardpath=r\"C:\\Users\\kyohe\\Aerial-Photo-Classifier\\20241023Data\\History\"\n",
    "\n",
    "pathlist=list(sorted(Path(testpath).glob(\"*\\*\")))\n",
    "filelist=[]\n",
    "for i in range(len(pathlist)):\n",
    "    filelist.append(str(pathlist[i]).split(\"\\\\\")[-1])\n",
    "\n",
    "print(np.array(filelist).shape)\n",
    "\n",
    "\n",
    "'''\n",
    "PytorchではDataloaderという,膨大なデータセットからでもメモリを圧迫せずに取り出せてforループにも対応するための枠組みがある\n",
    "データセットをDataloaderが引っ張ってこれるような形式にするためにMyDataset(torch.utils.data.Dataset)というクラスを作れば，\n",
    "あとはそのメソッドをtorch.utils.data.Datasetが勝手に使用してデータを加工してくれる\n",
    "__init__, __getitem__, __len__をクラス内で必ず定義しなければならない\n",
    "Dataloader内のデータはバッチごとにまとめられる\n",
    "'''\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, transforms, Classes) -> None:\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.Classes = Classes\n",
    "        #globは複数のファイルのパスをまとめて取得する\n",
    "        #訓練と訓練白黒の二個下のディレクトリから画像を取得\n",
    "        self.data = data\n",
    "\n",
    "    # ここで取り出すデータを指定している\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        data = self.data[index]\n",
    "        #OpenCVで読み込むときは必ずRGBに変換\n",
    "        img1 = cv2.cvtColor(cv2.imread(str(data)), cv2.COLOR_BGR2RGB)\n",
    "        img1 = cv2.resize(img1, (IMG_SIZE, IMG_SIZE))\n",
    "        img1 = TF.to_tensor(img1)\n",
    "\n",
    "        # データの変形 (transforms)\n",
    "        transformed_img = self.transforms(img1)\n",
    "\n",
    "        #ラベル貼り：dataというパスを/で区切ってリストにし，クラス名のところをラベルに格納\n",
    "        #クラス名は文字列なので，self.Classesの要素と比較して一致するところの番号をラベルとする\n",
    "        label = str(data).split(\"\\\\\")[-2]\n",
    "        label = torch.tensor(self.Classes.index(label))\n",
    "\n",
    "        return transformed_img, label\n",
    "\n",
    "    # この method がないと DataLoader を呼び出す際にエラーを吐かれる\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "#入力データに施す処理\n",
    "transforms = v2.Compose([\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0,0,0], std=[0.2, 0.2, 0.2]),\n",
    "])\n",
    "\n",
    "testset= MyDataset(data=pathlist, transforms=transforms, Classes=Classes)\n",
    "\n",
    "testloader = DataLoader(dataset=testset,batch_size=len(testset),shuffle=False)\n",
    "print(len(testloader))\n",
    "\n",
    "resnet50 = models.resnet50()\n",
    "\n",
    "#modify first layer so it expects 4 input channels; all other parameters unchanged\n",
    "resnet50.conv1 = torch.nn.Conv2d(Channels,64,kernel_size = (7,7),stride = (2,2), padding = (3,3), bias = False)\n",
    "#modifying final layer\n",
    "resnet50.fc = nn.Linear(2048,ClassNum)\n",
    "\n",
    "#lossfunction&optimizer\n",
    "#二値なのでBinaryCrossEntropy\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def evaluate(testloader, model, loss_fn, optimizer):\n",
    "    size_test = len(testloader.dataset)\n",
    "    test_loss, test_correct = 0, 0\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    model.eval()\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(torch.sigmoid(pred), y).item()\n",
    "            test_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        test_correct /= size_test\n",
    "\n",
    "    print(f'TestLoss: {test_loss:.4f} TestAcc: {test_correct:.4f}')\n",
    "\n",
    "    #ndarrayにするため、ラベルyと推測結果predをgpuからcpuへ返す\n",
    "    y=y.to(cpu)\n",
    "    pred=pred.to(cpu)\n",
    "\n",
    "    y=np.array(y)\n",
    "\n",
    "    #predは各クラスの確率になってる（onehotに近い）ので実際のクラス番号に戻す\n",
    "    pred_class=pred.argmax(1)\n",
    "    pred_class=np.array(pred_class)\n",
    "\n",
    "\n",
    "    #テストデータの混同行列を計算し可視化\n",
    "    #scikitlearnの混同行列はラベルをonehotではなく実際のクラス番号にする必要がある\n",
    "    #混同行列の見方は行が正解ラベルのクラス列が推定クラス\n",
    "    print(confusion_matrix(y, pred_class))\n",
    "    print(\" \")\n",
    "    csvpath=str(Path(forwardpath+\"\\\\\"+filedate+\"_ep\"+str(target_epoch)+\".csv\"))\n",
    "    chart=pd.DataFrame(pred_class, columns=['CLASS'], index=filelist)\n",
    "    chart.to_csv(csvpath)\n",
    "    print(chart)\n",
    "    print(\"CSV saved in \", csvpath)\n",
    "\n",
    "\n",
    "#モデル構築\n",
    "modelpath = Path(savepath+\"\\\\\"+str(target_epoch)+\"\\model_weights\"+filedate+\".pth\")\n",
    "epochmodel = resnet50\n",
    "epochmodel.load_state_dict(torch.load(modelpath))\n",
    "#GPUにニューラルネットワークを渡す\n",
    "epochmodel=epochmodel.to(device)\n",
    "\n",
    "print(\"Model in Epoch\", target_epoch)\n",
    "#テストデータで評価\n",
    "evaluate(testloader, epochmodel, loss_fn, optimizer)\n",
    "\n",
    "print('Forwarding Complete!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
