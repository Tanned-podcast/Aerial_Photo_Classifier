{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15549511-7f9a-444c-a97f-3891f5f1c780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7ac97f-f716-4190-a46c-d84ad3c737a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20201023_1321'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(20201023)+\"_\"+str(1321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93001f56-0044-4deb-ab98-7dc72e5c9ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240130_1210\n",
      "Model in Epoch 10\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 159\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel in Epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m#テストデータで評価\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     evaluate(testloader, epochmodel, loss_fn, optimizer)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting Complete!!!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 121\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(testloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m testloader:\n\u001b[0;32m    122\u001b[0m         X\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    123\u001b[0m         y\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_environment\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_environment\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_environment\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_environment\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     57\u001b[0m         index: \u001b[38;5;28mint\u001b[39m\n\u001b[0;32m     58\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[1;32m---> 61\u001b[0m     data2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata2[index]\n\u001b[0;32m     63\u001b[0m     img1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mstr\u001b[39m(data))\n\u001b[0;32m     64\u001b[0m     img1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img1, (IMG_SIZE, IMG_SIZE))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "date=20240130\n",
    "time=1210\n",
    "filedate=str(date)+\"_\"+str(time)\n",
    "print(filedate)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "Channels=4\n",
    "IMG_SIZE=224\n",
    "epochlist=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "\n",
    "Classes = [\"higainashi\", \"houdo\", \"kanbotsu\", \"rokatahoukai\"]\n",
    "ClassNum = len(Classes)\n",
    "\n",
    "testpath=r\"C:\\Users\\AKIZUKI\\JupyterProjects\\QGISedited\\test_ishikawa\"\n",
    "savepath=r\"C:\\Users\\AKIZUKI\\JupyterProjects\\AerialPhoto_savedmodel\"\n",
    "\n",
    "'''\n",
    "PytorchではDataloaderという,膨大なデータセットからでもメモリを圧迫せずに取り出せてforループにも対応するための枠組みがある\n",
    "データセットをDataloaderが引っ張ってこれるような形式にするためにMyDataset(torch.utils.data.Dataset)というクラスを作れば，\n",
    "あとはそのメソッドをtorch.utils.data.Datasetが勝手に使用してデータを加工してくれる\n",
    "__init__, __getitem__, __len__をクラス内で必ず定義しなければならない\n",
    "Dataloader内のデータはバッチごとにまとめられる\n",
    "'''\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root: str, transforms, Classes) -> None:\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.Classes = Classes\n",
    "        #globは複数のファイルのパスをまとめて取得する\n",
    "        #訓練と訓練白黒の二個下のディレクトリから画像を取得\n",
    "        self.data = list(sorted(Path(root).glob(\"*\\*\")))\n",
    "        self.data2 = list(sorted(Path(root+\"binary\").glob(\"*\\*\")))\n",
    "\n",
    "\n",
    "\n",
    "    # ここで取り出すデータを指定している\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        data = self.data[index]\n",
    "        data2 = self.data2[index]\n",
    "\n",
    "        img1 = cv2.imread(str(data))\n",
    "        img1 = cv2.resize(img1, (IMG_SIZE, IMG_SIZE))\n",
    "        img2_tmp = cv2.imread(str(data2))\n",
    "\n",
    "        # グレースケールに変換\n",
    "        img2_tmp = cv2.cvtColor(img2_tmp,cv2.COLOR_BGR2GRAY)\n",
    "        # 2値化\n",
    "        ret,img2 = cv2.threshold(img2_tmp, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "        img2 = cv2.resize(img2, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        #img1のテンソルとimg2のテンソルをチャンネル方向(dim0)に結合\n",
    "        cat_img = torch.cat((TF.to_tensor(img1), TF.to_tensor(img2)), dim=0)\n",
    "\n",
    "        # データの変形 (transforms)\n",
    "        transformed_img = self.transforms(cat_img)\n",
    "\n",
    "        #ラベル貼り：dataというパスを/で区切ってリストにし，クラス名のところをラベルに格納\n",
    "        #クラス名は文字列なので，self.Classesの要素と比較して一致するところの番号をラベルとする\n",
    "        label = str(data).split(\"\\\\\")[-2]\n",
    "        label = torch.tensor(self.Classes.index(label))\n",
    "\n",
    "        return transformed_img, label\n",
    "\n",
    "    # この method がないと DataLoader を呼び出す際にエラーを吐かれる\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "#入力データに施す処理\n",
    "transforms = v2.Compose([\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0,0,0,0], std=[0.2, 0.2, 0.2, 0.2]),\n",
    "])\n",
    "\n",
    "testset= MyDataset(root=testpath, transforms=transforms, Classes=Classes)\n",
    "\n",
    "testloader = DataLoader(dataset=testset,batch_size=len(testset),shuffle=True)\n",
    "\n",
    "resnet50 = models.resnet50()\n",
    "\n",
    "resnet50.conv1 = torch.nn.Conv2d(Channels,64,kernel_size = (7,7),stride = (2,2), padding = (3,3), bias = False)\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "#modifying final layer\n",
    "resnet50.fc = nn.Linear(num_ftrs,ClassNum)\n",
    "\n",
    "\n",
    "#lossfunction&optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def evaluate(testloader, model, loss_fn, optimizer):\n",
    "    size_test = len(testloader.dataset)\n",
    "    test_loss, test_correct = 0, 0\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    model.eval()\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            test_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        test_correct /= size_test\n",
    "\n",
    "    print(f'TestLoss: {test_loss:.4f} TestAcc: {test_correct:.4f}')\n",
    "\n",
    "    #ndarrayにするため、ラベルyと推測結果predをgpuからcpuへ返す\n",
    "    y=y.to(cpu)\n",
    "    pred=pred.to(cpu)\n",
    "   \n",
    "    y=np.array(y)\n",
    "\n",
    "    #predは各クラスの確率になってる（onehotに近い）ので実際のクラス番号に戻す\n",
    "    pred_class=pred.argmax(1)\n",
    "    pred_class=np.array(pred_class)\n",
    "    \n",
    "    \n",
    "    #テストデータの混同行列を計算し可視化\n",
    "    #scikitlearnの混同行列はラベルをonehotではなく実際のクラス番号にする必要がある\n",
    "    #混同行列の見方は行が正解ラベルのクラス列が推定クラス\n",
    "    print(confusion_matrix(y, pred_class))\n",
    "    print(\" \")\n",
    "\n",
    "for e in epochlist:\n",
    "    #モデル構築\n",
    "    modelpath = Path(savepath+\"\\\\\"+str(e)+\"\\model_weights\"+filedate+\".pth\")\n",
    "    epochmodel = resnet50\n",
    "    epochmodel.load_state_dict(torch.load(modelpath))\n",
    "    #GPUにニューラルネットワークを渡す\n",
    "    epochmodel=epochmodel.to(device)\n",
    "\n",
    "    print(\"Model in Epoch\", e)\n",
    "    #テストデータで評価\n",
    "    evaluate(testloader, epochmodel, loss_fn, optimizer)\n",
    "\n",
    "print('Testing Complete!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
